# ‚öôÔ∏è Setup Chat - Configura√ß√£o Llama 3.2

Guia completo para configura√ß√£o do chatbot com Ollama e Llama 3.2.

## üöÄ Instala√ß√£o Ollama

### Windows
```cmd
# Download e instalar Ollama
winget install Ollama.Ollama

# Ou baixar de: https://ollama.ai/download/windows
```

### Linux/macOS
```bash
# Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh
```

## ü§ñ Configura√ß√£o Llama 3.2

### Download do Modelo
```bash
# Baixar Llama 3.2 (3B par√¢metros)
ollama pull llama3.2

# Verificar modelos instalados
ollama list
```

### Iniciar Servi√ßo
```bash
# Iniciar servidor Ollama
ollama serve

# Verificar status
curl http://localhost:11434/api/tags
```

## üîß Configura√ß√£o Backend

### Vari√°veis de Ambiente (.env)
```env
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_TIMEOUT=120
```

### Teste de Conex√£o
```python
# Backend/test_ollama.py
import requests

def test_ollama():
    try:
        response = requests.get("http://localhost:11434/api/tags")
        print("‚úÖ Ollama conectado:", response.json())
    except:
        print("‚ùå Ollama n√£o conectado")

test_ollama()
```

## üéØ Configura√ß√£o de Prompts

### Sistema Base
```python
SYSTEM_PROMPT = """
Voc√™ √© EKKO, assistente de agricultura sustent√°vel.
Especialista em an√°lise de solo, culturas e sustentabilidade.
Responda de forma pr√°tica e educativa.
"""
```

### Contexto RAG
```python
def build_context(unity_id):
    user_data = get_user_data(unity_id)
    return f"""
    Dados do usu√°rio:
    - Solo: pH {user_data['ph']}, NPK {user_data['npk']}
    - Localiza√ß√£o: {user_data['location']}
    - Culturas: {user_data['crops']}
    """
```

## üîç Troubleshooting

### Problemas Comuns
1. **Ollama n√£o inicia**: Verificar porta 11434
2. **Modelo n√£o encontrado**: Executar `ollama pull llama3.2`
3. **Timeout**: Aumentar OLLAMA_TIMEOUT
4. **Mem√≥ria insuficiente**: Usar modelo menor

### Logs e Debug
```bash
# Ver logs Ollama
ollama logs

# Testar modelo diretamente
ollama run llama3.2 "Teste de conex√£o"
```