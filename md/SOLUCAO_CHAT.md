# ðŸ”§ SoluÃ§Ã£o Chat - Troubleshooting

Guia de soluÃ§Ã£o de problemas do sistema de chat EKKO.

## ðŸš¨ Problemas Comuns

### 1. **Ollama nÃ£o conecta**

**Sintomas:**
- Erro "Connection refused" na porta 11434
- Chat nÃ£o responde
- Health check falha

**SoluÃ§Ãµes:**
```bash
# Verificar se Ollama estÃ¡ rodando
curl http://localhost:11434/api/tags

# Iniciar Ollama
ollama serve

# Verificar processo
ps aux | grep ollama  # Linux/macOS
tasklist | findstr ollama  # Windows
```

### 2. **Modelo Llama 3.2 nÃ£o encontrado**

**Sintomas:**
- Erro "model not found"
- Resposta vazia do chat

**SoluÃ§Ãµes:**
```bash
# Baixar modelo
ollama pull llama3.2

# Verificar modelos instalados
ollama list

# Testar modelo
ollama run llama3.2 "teste"
```

### 3. **MongoDB nÃ£o conecta**

**Sintomas:**
- Erro de conexÃ£o com banco
- Contexto do usuÃ¡rio nÃ£o carrega

**SoluÃ§Ãµes:**
```python
# Testar conexÃ£o MongoDB
python Backend/test_mongo.py

# Verificar .env
MONGO_URI=mongodb+srv://user:pass@cluster.mongodb.net/
MONGO_DB_NAME=EKKOnUnity
```

### 4. **Streaming nÃ£o funciona**

**Sintomas:**
- Resposta aparece toda de uma vez
- EventSource nÃ£o conecta

**SoluÃ§Ãµes:**
```javascript
// Verificar EventSource
const eventSource = new EventSource(`/api/chat/${unityId}`);
eventSource.onerror = (error) => {
    console.error('EventSource error:', error);
};

// Fallback para polling
if (!window.EventSource) {
    // Implementar polling
}
```

## ðŸ” Debug e Logs

### Backend Logs
```python
# Ativar logs detalhados
import logging
logging.basicConfig(level=logging.DEBUG)

# Log especÃ­fico do chat
logger = logging.getLogger("chat")
logger.debug(f"Mensagem recebida: {message}")
```

### Frontend Debug
```javascript
// Console debug
console.log('Unity ID:', unityId);
console.log('Mensagem enviada:', message);

// Network tab para verificar requests
// DevTools â†’ Network â†’ XHR/Fetch
```

### Ollama Debug
```bash
# Logs detalhados Ollama
OLLAMA_DEBUG=1 ollama serve

# Verificar uso de memÃ³ria
ollama ps

# Logs do sistema
journalctl -u ollama  # Linux
```

## âš¡ Performance Issues

### 1. **Resposta lenta**

**Causas:**
- Modelo muito grande
- Pouca memÃ³ria RAM
- Contexto muito longo

**SoluÃ§Ãµes:**
```env
# Reduzir timeout
OLLAMA_TIMEOUT=60

# Limitar tokens
OLLAMA_MAX_TOKENS=1024

# Usar modelo menor
OLLAMA_MODEL=llama3.2:1b
```

### 2. **MemÃ³ria insuficiente**

**Sintomas:**
- Ollama trava
- Sistema lento
- Out of memory errors

**SoluÃ§Ãµes:**
```bash
# Verificar uso de memÃ³ria
free -h  # Linux
wmic OS get TotalVisibleMemorySize,FreePhysicalMemory  # Windows

# Usar modelo menor
ollama pull llama3.2:1b
```

## ðŸ› ï¸ Ferramentas de Debug

### Health Check Completo
```python
# Backend/debug_health.py
def full_health_check():
    # Testar Ollama
    # Testar MongoDB
    # Testar endpoints
    # Gerar relatÃ³rio
```

### Monitor de Performance
```javascript
// Frontend performance monitor
const perfMonitor = {
    startTime: Date.now(),
    measureResponse: () => {
        return Date.now() - perfMonitor.startTime;
    }
};
```

### Logs Estruturados
```python
# Formato JSON para logs
import json
import datetime

def log_chat_event(event, data):
    log_entry = {
        "timestamp": datetime.datetime.now().isoformat(),
        "event": event,
        "data": data
    }
    print(json.dumps(log_entry))
```

## ðŸ“ž Suporte

### Checklist de DiagnÃ³stico
- [ ] Ollama rodando na porta 11434
- [ ] Modelo llama3.2 instalado
- [ ] MongoDB conectado
- [ ] .env configurado corretamente
- [ ] Firewall/antivÃ­rus nÃ£o bloqueando
- [ ] MemÃ³ria RAM suficiente (>4GB)
- [ ] Navegador suporta EventSource